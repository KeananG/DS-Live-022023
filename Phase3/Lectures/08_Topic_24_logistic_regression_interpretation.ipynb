{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Cost-Functions-and-Solutions-To-the-Optimization-Problem\" data-toc-modified-id=\"Cost-Functions-and-Solutions-To-the-Optimization-Problem-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Cost Functions and Solutions To the Optimization Problem</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Bad-News\" data-toc-modified-id=\"The-Bad-News-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>The Bad News</a></span></li><li><span><a href=\"#The-Good-News\" data-toc-modified-id=\"The-Good-News-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>The Good News</a></span><ul class=\"toc-item\"><li><span><a href=\"#ðŸ§ -Knowledge-Check\" data-toc-modified-id=\"ðŸ§ -Knowledge-Check-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>ðŸ§  Knowledge Check</a></span></li><li><span><a href=\"#More-Log-Loss-Resources\" data-toc-modified-id=\"More-Log-Loss-Resources-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>More Log-Loss Resources</a></span></li></ul></li></ul></li><li><span><a href=\"#Digging-Deeper-into-Logistic-Regression\" data-toc-modified-id=\"Digging-Deeper-into-Logistic-Regression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Digging Deeper into Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preparing-Data\" data-toc-modified-id=\"Preparing-Data-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Preparing Data</a></span></li><li><span><a href=\"#Train-Logistic-Regression\" data-toc-modified-id=\"Train-Logistic-Regression-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Train Logistic Regression</a></span></li><li><span><a href=\"#Interpreting-Logistic-Regression-Coefficients\" data-toc-modified-id=\"Interpreting-Logistic-Regression-Coefficients-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Interpreting Logistic Regression Coefficients</a></span></li></ul></li><li><span><a href=\"#Putting-It-All-Together:-Training-Logistic-Regression\" data-toc-modified-id=\"Putting-It-All-Together:-Training-Logistic-Regression-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Putting It All Together: Training Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-and-Explore-Data\" data-toc-modified-id=\"Load-and-Explore-Data-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Load and Explore Data</a></span></li><li><span><a href=\"#Create-and-Train-Logistic-Regression-Model\" data-toc-modified-id=\"Create-and-Train-Logistic-Regression-Model-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Create and Train Logistic Regression Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Optional:-Evaluate-the-Model-with-Cross-Validation\" data-toc-modified-id=\"Optional:-Evaluate-the-Model-with-Cross-Validation-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Optional: Evaluate the Model with Cross-Validation</a></span></li><li><span><a href=\"#Optional:-Rinse-and-Repeat---Multiple-Models\" data-toc-modified-id=\"Optional:-Rinse-and-Repeat---Multiple-Models-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Optional: Rinse and Repeat - Multiple Models</a></span></li></ul></li><li><span><a href=\"#Final-Evaluation\" data-toc-modified-id=\"Final-Evaluation-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Final Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-Set\" data-toc-modified-id=\"Training-Set-4.3.1\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Training Set</a></span></li><li><span><a href=\"#Testing-Set\" data-toc-modified-id=\"Testing-Set-4.3.2\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Testing Set</a></span></li></ul></li></ul></li><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Exercise</a></span></li><li><span><a href=\"#Level-Up\" data-toc-modified-id=\"Level-Up-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Level Up</a></span><ul class=\"toc-item\"><li><span><a href=\"#More-Generalizations:-Other-Link-Functions,-Other-Models\" data-toc-modified-id=\"More-Generalizations:-Other-Link-Functions,-Other-Models-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>More Generalizations: Other Link Functions, Other Models</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For our modeling steps\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# For demonstrative purposes\n",
    "from scipy.special import logit, expit\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Explain the form of logistic regression\n",
    "- Explain how to interpret logistic regression coefficients\n",
    "- Use logistic regression to perform a classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Cost Functions and Solutions To the Optimization Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Unlike the least-squares problem for linear regression, no one has yet found a closed-form solution to the optimization problem presented by logistic regression. But even if one exists, the computation would no doubt be so complex that we'd be better off using some sort of approximation method instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "But there's still a problem.\n",
    "\n",
    "Recall the cost function for linear regression: <br/><br/>\n",
    "$SSE = \\Sigma_i(y_i - \\hat{y}_i)^2 = \\Sigma_i(y_i - (\\beta_0 + \\beta_1x_{i1} + ... + \\beta_nx_{in}))^2$.\n",
    "\n",
    "This function, $SSE(\\vec{\\beta})$, is convex.\n",
    "\n",
    "If we plug in our new logistic equation for $\\hat{y}$, we get: <br/><br/>\n",
    "$SSE_{log} = \\Sigma_i(y_i - \\hat{y}_i)^2 = \\Sigma_i\\left(y_i - \\left(\\frac{1}{1+e^{-(\\beta_0 + \\beta_1x_{i1} + ... + \\beta_nx_{in})}}\\right)\\right)^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The Bad News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*This* function, $SSE_{log}(\\vec{\\beta})$, is [**not** convex](https://towardsdatascience.com/why-not-mse-as-a-loss-function-for-logistic-regression-589816b5e03c).\n",
    "\n",
    "That means that, if we tried to use gradient descent or some other approximation method that looks for the minimum of this function, we could easily find a local rather than a global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Note that the scikit-learn class *expects the user to specify the solver* to be used in calculating the coefficients. The default solver, [lbfgs](https://en.wikipedia.org/wiki/Limited-memory_BFGS), works well for many applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## The Good News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can use **log-loss** instead:\n",
    "\n",
    "$\\mathcal{L}(\\vec{y}, \\hat{\\vec{y}}) = -\\frac{1}{N}\\Sigma^N_{i=1}\\left(y_iln(\\hat{y}_i)+(1-y_i)ln(1-\\hat{y}_i)\\right)$,\n",
    "\n",
    "where $\\hat{y}_i$ is the probability that $(x_{i1}, ... , x_{in})$ belongs to **class 1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**More resources on the log-loss function**:\n",
    "\n",
    "https://towardsdatascience.com/optimization-loss-function-under-the-hood-part-ii-d20a239cde11\n",
    "\n",
    "https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ðŸ§  Knowledge Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Is a bigger value (more positive) better or worse than a smaller value?\n",
    "\n",
    "- Smaller is better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- What would the log-loss for one data point when the target is $0$ but we predict $1$?\n",
    "    - **Really large, essentially Positive infinity**\n",
    "\n",
    "- What would the log-loss for one data point when the target is $0$ but we predict $0$?\n",
    "    - **0 No loss**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Digging Deeper into Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.52320</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>71.75</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca   ba    fe  glass_type\n",
       "id                                                                        \n",
       "22   1.51966  14.77  3.75  0.29  72.02  0.03   9.00  0.0  0.00           1\n",
       "185  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.0  0.00           6\n",
       "40   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1\n",
       "39   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1\n",
       "51   1.52320  13.72  3.72  0.51  71.75  0.09  10.06  0.0  0.16           1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glass identification dataset\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/glass/glass.data'\n",
    "col_names = ['id','ri','na','mg','al','si','k','ca','ba','fe','glass_type']\n",
    "glass = pd.read_csv(url, names=col_names, index_col='id')\n",
    "glass.sort_values('al', inplace=True)\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ri</th>\n",
       "      <th>na</th>\n",
       "      <th>mg</th>\n",
       "      <th>al</th>\n",
       "      <th>si</th>\n",
       "      <th>k</th>\n",
       "      <th>ca</th>\n",
       "      <th>ba</th>\n",
       "      <th>fe</th>\n",
       "      <th>glass_type</th>\n",
       "      <th>household</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.51966</td>\n",
       "      <td>14.77</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.29</td>\n",
       "      <td>72.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.51115</td>\n",
       "      <td>17.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>75.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.52213</td>\n",
       "      <td>14.21</td>\n",
       "      <td>3.82</td>\n",
       "      <td>0.47</td>\n",
       "      <td>71.77</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>1.52320</td>\n",
       "      <td>13.72</td>\n",
       "      <td>3.72</td>\n",
       "      <td>0.51</td>\n",
       "      <td>71.75</td>\n",
       "      <td>0.09</td>\n",
       "      <td>10.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ri     na    mg    al     si     k     ca   ba    fe  glass_type  \\\n",
       "id                                                                           \n",
       "22   1.51966  14.77  3.75  0.29  72.02  0.03   9.00  0.0  0.00           1   \n",
       "185  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.0  0.00           6   \n",
       "40   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "39   1.52213  14.21  3.82  0.47  71.77  0.11   9.57  0.0  0.00           1   \n",
       "51   1.52320  13.72  3.72  0.51  71.75  0.09  10.06  0.0  0.16           1   \n",
       "\n",
       "     household  \n",
       "id              \n",
       "22           0  \n",
       "185          1  \n",
       "40           0  \n",
       "39           0  \n",
       "51           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# types 1, 2, 3 are window glass\n",
    "# types 5, 6, 7 are household glass\n",
    "glass['household'] = glass.glass_type.map({1:0, 2:0, 3:0, 5:1, 6:1, 7:1})\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Train Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fit a logistic regression model and store the class predictions\n",
    "\n",
    "logreg = LogisticRegression(random_state=42)\n",
    "feature_cols = ['al']\n",
    "X = glass[feature_cols]\n",
    "y = glass.household\n",
    "logreg.fit(X, y)\n",
    "glass['household_pred_class'] = logreg.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36150680872607704"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y, logreg.predict_proba(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying by Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = logreg.predict_proba(X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36150680872607704"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.mean([y*np.log(y_hat) + (1-y)*np.log(1-y_hat)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Interpreting Logistic Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.11517927]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We do have coefs_ still, linear model\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How do we interpret the coefficients of a logistic regression? For a linear regression, the situaton was like this:\n",
    "\n",
    "- Linear Regression: We construct the best-fit line and get a set of coefficients. Suppose $\\beta_1 = k$. In that case we would expect a 1-unit change in $x_1$ to produce a $k$-unit change in $y$.\n",
    "\n",
    "- Logistic Regression: We find the coefficients of the best-fit line by some approximation method. Suppose $\\beta_1 = k$. In that case we would expect a 1-unit change in $x_1$ to produce a $k$-unit change (not in $y$ but) in $ln\\left(\\frac{y}{1-y}\\right)$.\n",
    "\n",
    "We have:\n",
    "\n",
    "$\\ln\\left(\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)}\\right) = \\ln\\left(\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}\\right) + k$.\n",
    "\n",
    "Exponentiating both sides:\n",
    "\n",
    "$\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)} = e^{\\ln\\left(\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}\\right) + k}$ <br/><br/> $\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)}= e^{\\ln\\left(\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}\\right)}\\cdot e^k$ <br/><br/> $\\frac{y(x_1+1, ... , x_n)}{1-y(x_1+1, ... , x_n)}= e^k\\cdot\\frac{y(x_1, ... , x_n)}{1-y(x_1, ... , x_n)}$\n",
    "\n",
    "That is, the odds ratio at $x_1+1$ has increased by a factor of $e^k$ relative to the odds ratio at $x_1$.\n",
    "\n",
    "For more on interpretation, see [this page](https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/how-to/binary-logistic-regression/interpret-the-results/all-statistics-and-graphs/coefficients/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.00934605])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the intercept\n",
    "\n",
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Interpretation:** For an 'al' value of 0, the log-odds of 'household' is -6.01. What is the probability that glass with an 'al' value of 0 is household glass?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00244968])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert log-odds to probability\n",
    "\n",
    "logodds = logreg.intercept_\n",
    "odds = np.exp(logodds)\n",
    "prob = odds / (1 + odds)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99755032, 0.00244968]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as \n",
    "logreg.predict_proba([[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('al', 3.1151792681570165)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the coefficient for al\n",
    "\n",
    "list(zip(feature_cols, logreg.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Interpretation:** A 1 unit increase in 'al' is associated with a 3.12-unit increase in the log-odds of 'household'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Aside: Verifying log-odds to probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's verify this as we change the aluminum content from 1 to 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94755733, 0.05244267]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction for al=1\n",
    "\n",
    "pred_al1 = logreg.predict_proba([[1]])\n",
    "pred_al1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.055345120235735255"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Odds ratio for al=1\n",
    "\n",
    "odds_al1 = pred_al1[0][1] / pred_al1[0][0]\n",
    "odds_al1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4449707, 0.5550293]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction for al=2\n",
    "pred_al2 = logreg.predict_proba([[2]])\n",
    "pred_al2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2473390003597828"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Odds ratio for al=2\n",
    "\n",
    "odds_al2 = pred_al2[0][1] / pred_al2[0][0]\n",
    "odds_al2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2473390003597826\n",
      "1.2473390003597828\n"
     ]
    }
   ],
   "source": [
    "print((np.exp(logreg.coef_[0]) * odds_al1)[0])\n",
    "print(odds_al2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Aside: Use Coefficients to Generate Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22101248])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute predicted log-odds for al=2 using the equation\n",
    "x_al = 2\n",
    "logodds = logreg.intercept_ + logreg.coef_[0] * x_al\n",
    "logodds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fabffc460d0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_al_logodds = np.arange(0.29,3.51,.01)\n",
    "y_logodds = logreg.intercept_ + logreg.coef_[0] * x_al_logodds\n",
    "plt.plot(x_al_logodds, y_logodds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.247339])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert log-odds to odds\n",
    "\n",
    "odds = np.exp(logodds)\n",
    "odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5550293])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert odds to probability\n",
    "\n",
    "prob = odds / (1 + odds)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5550293])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute predicted probability for al=2 using the predict_proba method\n",
    "\n",
    "logreg.predict_proba(np.array([2.0]).reshape(1, 1))[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Putting It All Together: Training Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's take some time to show how you can do use logistic regression in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> Note we've been talking about _binary classification_ but we can also do classification for _multiclass_ problems (more than binary classes).\n",
    ">\n",
    "> That's what we'll do for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Built in dataset from sklearn\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=np.c_[iris['data'], iris['target']],\n",
    "    columns=iris['feature_names'] + ['target']\n",
    ")\n",
    "\n",
    "display(df.head())\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note how many different targets there are\n",
    "df.target.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can go ahead and explore some graphs to show that it doesn't make sense to do a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating a large figure\n",
    "fig = plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Iterating over the different\n",
    "for i in range(0, 4):\n",
    "    # Figure number starts at 1\n",
    "    ax = fig.add_subplot(2, 2, i+1)\n",
    "    # Add a title to make it clear what each subplot shows\n",
    "    plt.title(df.columns[i])\n",
    "    # Use alpha to better see crossing pints\n",
    "    ax.scatter(df.iloc[:, i], df['target'], c='teal', alpha=0.1)\n",
    "    # Only show the tick marks for each target\n",
    "    plt.yticks(df.target.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Preparing the data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get the features and then the target\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80377277, 0.55160877, 0.22064351, 0.0315205 ],\n",
       "       [0.82813287, 0.50702013, 0.23660939, 0.03380134],\n",
       "       [0.80533308, 0.54831188, 0.2227517 , 0.03426949],\n",
       "       [0.80003025, 0.53915082, 0.26087943, 0.03478392],\n",
       "       [0.790965  , 0.5694948 , 0.2214702 , 0.0316386 ],\n",
       "       [0.78417499, 0.5663486 , 0.2468699 , 0.05808704],\n",
       "       [0.78010936, 0.57660257, 0.23742459, 0.0508767 ],\n",
       "       [0.80218492, 0.54548574, 0.24065548, 0.0320874 ],\n",
       "       [0.80642366, 0.5315065 , 0.25658935, 0.03665562],\n",
       "       [0.81803119, 0.51752994, 0.25041771, 0.01669451],\n",
       "       [0.80373519, 0.55070744, 0.22325977, 0.02976797],\n",
       "       [0.786991  , 0.55745196, 0.26233033, 0.03279129],\n",
       "       [0.82307218, 0.51442011, 0.24006272, 0.01714734],\n",
       "       [0.8025126 , 0.55989251, 0.20529392, 0.01866308],\n",
       "       [0.81120865, 0.55945424, 0.16783627, 0.02797271],\n",
       "       [0.77381111, 0.59732787, 0.2036345 , 0.05430253],\n",
       "       [0.79428944, 0.57365349, 0.19121783, 0.05883625],\n",
       "       [0.80327412, 0.55126656, 0.22050662, 0.04725142],\n",
       "       [0.8068282 , 0.53788547, 0.24063297, 0.04246464],\n",
       "       [0.77964883, 0.58091482, 0.22930848, 0.0458617 ],\n",
       "       [0.8173379 , 0.51462016, 0.25731008, 0.03027177],\n",
       "       [0.78591858, 0.57017622, 0.23115252, 0.06164067],\n",
       "       [0.77577075, 0.60712493, 0.16864581, 0.03372916],\n",
       "       [0.80597792, 0.52151512, 0.26865931, 0.07901744],\n",
       "       [0.776114  , 0.54974742, 0.30721179, 0.03233808],\n",
       "       [0.82647451, 0.4958847 , 0.26447184, 0.03305898],\n",
       "       [0.79778206, 0.5424918 , 0.25529026, 0.06382256],\n",
       "       [0.80641965, 0.54278246, 0.23262105, 0.03101614],\n",
       "       [0.81609427, 0.5336001 , 0.21971769, 0.03138824],\n",
       "       [0.79524064, 0.54144043, 0.27072022, 0.03384003],\n",
       "       [0.80846584, 0.52213419, 0.26948861, 0.03368608],\n",
       "       [0.82225028, 0.51771314, 0.22840286, 0.06090743],\n",
       "       [0.76578311, 0.60379053, 0.22089897, 0.0147266 ],\n",
       "       [0.77867447, 0.59462414, 0.19820805, 0.02831544],\n",
       "       [0.81768942, 0.51731371, 0.25031309, 0.03337508],\n",
       "       [0.82512295, 0.52807869, 0.19802951, 0.03300492],\n",
       "       [0.82699754, 0.52627116, 0.19547215, 0.03007264],\n",
       "       [0.78523221, 0.5769053 , 0.22435206, 0.01602515],\n",
       "       [0.80212413, 0.54690282, 0.23699122, 0.03646019],\n",
       "       [0.80779568, 0.53853046, 0.23758697, 0.03167826],\n",
       "       [0.80033301, 0.56023311, 0.20808658, 0.04801998],\n",
       "       [0.86093857, 0.44003527, 0.24871559, 0.0573959 ],\n",
       "       [0.78609038, 0.57170209, 0.23225397, 0.03573138],\n",
       "       [0.78889479, 0.55222635, 0.25244633, 0.09466737],\n",
       "       [0.76693897, 0.57144472, 0.28572236, 0.06015208],\n",
       "       [0.82210585, 0.51381615, 0.23978087, 0.05138162],\n",
       "       [0.77729093, 0.57915795, 0.24385598, 0.030482  ],\n",
       "       [0.79594782, 0.55370283, 0.24224499, 0.03460643],\n",
       "       [0.79837025, 0.55735281, 0.22595384, 0.03012718],\n",
       "       [0.81228363, 0.5361072 , 0.22743942, 0.03249135],\n",
       "       [0.76701103, 0.35063361, 0.51499312, 0.15340221],\n",
       "       [0.74549757, 0.37274878, 0.52417798, 0.17472599],\n",
       "       [0.75519285, 0.33928954, 0.53629637, 0.16417236],\n",
       "       [0.75384916, 0.31524601, 0.54825394, 0.17818253],\n",
       "       [0.7581754 , 0.32659863, 0.5365549 , 0.17496355],\n",
       "       [0.72232962, 0.35482858, 0.57026022, 0.16474184],\n",
       "       [0.72634846, 0.38046824, 0.54187901, 0.18446945],\n",
       "       [0.75916547, 0.37183615, 0.51127471, 0.15493173],\n",
       "       [0.76301853, 0.33526572, 0.53180079, 0.15029153],\n",
       "       [0.72460233, 0.37623583, 0.54345175, 0.19508524],\n",
       "       [0.76923077, 0.30769231, 0.53846154, 0.15384615],\n",
       "       [0.73923462, 0.37588201, 0.52623481, 0.187941  ],\n",
       "       [0.78892752, 0.28927343, 0.52595168, 0.13148792],\n",
       "       [0.73081412, 0.34743622, 0.56308629, 0.16772783],\n",
       "       [0.75911707, 0.3931142 , 0.48800383, 0.17622361],\n",
       "       [0.76945444, 0.35601624, 0.50531337, 0.16078153],\n",
       "       [0.70631892, 0.37838513, 0.5675777 , 0.18919257],\n",
       "       [0.75676497, 0.35228714, 0.53495455, 0.13047672],\n",
       "       [0.76444238, 0.27125375, 0.55483721, 0.18494574],\n",
       "       [0.76185188, 0.34011245, 0.53057542, 0.14964948],\n",
       "       [0.6985796 , 0.37889063, 0.56833595, 0.21312598],\n",
       "       [0.77011854, 0.35349703, 0.50499576, 0.16412362],\n",
       "       [0.74143307, 0.29421947, 0.57667016, 0.17653168],\n",
       "       [0.73659895, 0.33811099, 0.56754345, 0.14490471],\n",
       "       [0.76741698, 0.34773582, 0.51560829, 0.15588157],\n",
       "       [0.76785726, 0.34902603, 0.51190484, 0.16287881],\n",
       "       [0.76467269, 0.31486523, 0.53976896, 0.15743261],\n",
       "       [0.74088576, 0.33173989, 0.55289982, 0.18798594],\n",
       "       [0.73350949, 0.35452959, 0.55013212, 0.18337737],\n",
       "       [0.78667474, 0.35883409, 0.48304589, 0.13801311],\n",
       "       [0.76521855, 0.33391355, 0.52869645, 0.15304371],\n",
       "       [0.77242925, 0.33706004, 0.51963422, 0.14044168],\n",
       "       [0.76434981, 0.35581802, 0.51395936, 0.15814134],\n",
       "       [0.70779525, 0.31850786, 0.60162596, 0.1887454 ],\n",
       "       [0.69333409, 0.38518561, 0.57777841, 0.1925928 ],\n",
       "       [0.71524936, 0.40530797, 0.53643702, 0.19073316],\n",
       "       [0.75457341, 0.34913098, 0.52932761, 0.16893434],\n",
       "       [0.77530021, 0.28304611, 0.54147951, 0.15998258],\n",
       "       [0.72992443, 0.39103094, 0.53440896, 0.16944674],\n",
       "       [0.74714194, 0.33960997, 0.54337595, 0.17659719],\n",
       "       [0.72337118, 0.34195729, 0.57869695, 0.15782644],\n",
       "       [0.73260391, 0.36029701, 0.55245541, 0.1681386 ],\n",
       "       [0.76262994, 0.34186859, 0.52595168, 0.1577855 ],\n",
       "       [0.76986879, 0.35413965, 0.5081134 , 0.15397376],\n",
       "       [0.73544284, 0.35458851, 0.55158213, 0.1707278 ],\n",
       "       [0.73239618, 0.38547167, 0.53966034, 0.15418867],\n",
       "       [0.73446047, 0.37367287, 0.5411814 , 0.16750853],\n",
       "       [0.75728103, 0.3542121 , 0.52521104, 0.15878473],\n",
       "       [0.78258054, 0.38361791, 0.4603415 , 0.16879188],\n",
       "       [0.7431482 , 0.36505526, 0.5345452 , 0.16948994],\n",
       "       [0.65387747, 0.34250725, 0.62274045, 0.25947519],\n",
       "       [0.69052512, 0.32145135, 0.60718588, 0.22620651],\n",
       "       [0.71491405, 0.30207636, 0.59408351, 0.21145345],\n",
       "       [0.69276796, 0.31889319, 0.61579374, 0.1979337 ],\n",
       "       [0.68619022, 0.31670318, 0.61229281, 0.232249  ],\n",
       "       [0.70953708, 0.28008043, 0.61617694, 0.1960563 ],\n",
       "       [0.67054118, 0.34211284, 0.61580312, 0.23263673],\n",
       "       [0.71366557, 0.28351098, 0.61590317, 0.17597233],\n",
       "       [0.71414125, 0.26647062, 0.61821183, 0.19185884],\n",
       "       [0.69198788, 0.34599394, 0.58626751, 0.24027357],\n",
       "       [0.71562645, 0.3523084 , 0.56149152, 0.22019275],\n",
       "       [0.71576546, 0.30196356, 0.59274328, 0.21249287],\n",
       "       [0.71718148, 0.31640359, 0.58007326, 0.22148252],\n",
       "       [0.6925518 , 0.30375079, 0.60750157, 0.24300063],\n",
       "       [0.67767924, 0.32715549, 0.59589036, 0.28041899],\n",
       "       [0.69589887, 0.34794944, 0.57629125, 0.25008866],\n",
       "       [0.70610474, 0.3258945 , 0.59747324, 0.1955367 ],\n",
       "       [0.69299099, 0.34199555, 0.60299216, 0.19799743],\n",
       "       [0.70600618, 0.2383917 , 0.63265489, 0.21088496],\n",
       "       [0.72712585, 0.26661281, 0.60593821, 0.18178146],\n",
       "       [0.70558934, 0.32722984, 0.58287815, 0.23519645],\n",
       "       [0.68307923, 0.34153961, 0.59769433, 0.24395687],\n",
       "       [0.71486543, 0.25995106, 0.62202576, 0.18567933],\n",
       "       [0.73122464, 0.31338199, 0.56873028, 0.20892133],\n",
       "       [0.69595601, 0.3427843 , 0.59208198, 0.21813547],\n",
       "       [0.71529453, 0.31790868, 0.59607878, 0.17882363],\n",
       "       [0.72785195, 0.32870733, 0.56349829, 0.21131186],\n",
       "       [0.71171214, 0.35002236, 0.57170319, 0.21001342],\n",
       "       [0.69594002, 0.30447376, 0.60894751, 0.22835532],\n",
       "       [0.73089855, 0.30454106, 0.58877939, 0.1624219 ],\n",
       "       [0.72766159, 0.27533141, 0.59982915, 0.18683203],\n",
       "       [0.71578999, 0.34430405, 0.5798805 , 0.18121266],\n",
       "       [0.69417747, 0.30370264, 0.60740528, 0.2386235 ],\n",
       "       [0.72366005, 0.32162669, 0.58582004, 0.17230001],\n",
       "       [0.69385414, 0.29574111, 0.63698085, 0.15924521],\n",
       "       [0.73154399, 0.28501714, 0.57953485, 0.21851314],\n",
       "       [0.67017484, 0.36168166, 0.59571097, 0.2553047 ],\n",
       "       [0.69804799, 0.338117  , 0.59988499, 0.196326  ],\n",
       "       [0.71066905, 0.35533453, 0.56853524, 0.21320072],\n",
       "       [0.72415258, 0.32534391, 0.56672811, 0.22039426],\n",
       "       [0.69997037, 0.32386689, 0.58504986, 0.25073566],\n",
       "       [0.73337886, 0.32948905, 0.54206264, 0.24445962],\n",
       "       [0.69052512, 0.32145135, 0.60718588, 0.22620651],\n",
       "       [0.69193502, 0.32561648, 0.60035539, 0.23403685],\n",
       "       [0.68914871, 0.33943145, 0.58629069, 0.25714504],\n",
       "       [0.72155725, 0.32308533, 0.56001458, 0.24769876],\n",
       "       [0.72965359, 0.28954508, 0.57909015, 0.22005426],\n",
       "       [0.71653899, 0.3307103 , 0.57323119, 0.22047353],\n",
       "       [0.67467072, 0.36998072, 0.58761643, 0.25028107],\n",
       "       [0.69025916, 0.35097923, 0.5966647 , 0.21058754]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize the data to help the model\n",
    "X = normalize(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999998"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now each row vector has unit length\n",
    "sum([x**2 for x in X[0, :]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split for test & training  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Create and Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There's a lot of different parameters for `LogisticRegression`. Check out the documentation for more info: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "my_model = LogisticRegression(\n",
    "            C=1e3,             # Smaller values -> more regularization\n",
    "            max_iter=1e3,      # Ensure we eventually reach a solution\n",
    "            solver='lbfgs',    # (Default) Can optimize depending on problem\n",
    "            multi_class='ovr'  # (Default) Will try to do multiclass classification \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, max_iter=1000.0, multi_class='ovr')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit/Train the model\n",
    "my_model.fit(X_train, y_train)\n",
    "my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Optional: Evaluate the Model with Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In practice, we should make this a practice but we skip it if time is running low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "                    estimator=my_model,\n",
    "                    X=X_train,\n",
    "                    y=y_train,\n",
    "                    cv=5,\n",
    "                    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96875, 0.96875, 0.96875, 0.96875, 0.96875])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95833333, 0.95833333, 0.95833333, 0.95833333, 0.91666667])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cv_overall(cv_results):\n",
    "    val_results = cv_results['test_score']\n",
    "    result_str = f'{val_results.mean():.3f} Â± {val_results.std():.3f}'\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.950 Â± 0.017'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_overall(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's save these results for later\n",
    "models = {}\n",
    "\n",
    "models['model_1'] = {'model': my_model, 'cv':cv_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall Training Score\n",
    "my_model.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Optional: Rinse and Repeat - Multiple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's try out a few more models for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #2 with C=0.1\n",
      "Cross-validating model with training data...\n",
      "\tCross-Validation Score: 0.750 Â± 0.105\n",
      "Fitting model to full training set...\n",
      "\tScore on training set: 0.883\n",
      "Saving Results...\n",
      "\n",
      " ------------------------------ \n",
      "\n",
      "Model #3 with C=100.0\n",
      "Cross-validating model with training data...\n",
      "\tCross-Validation Score: 0.950 Â± 0.017\n",
      "Fitting model to full training set...\n",
      "\tScore on training set: 0.967\n",
      "Saving Results...\n",
      "\n",
      " ------------------------------ \n",
      "\n",
      "Model #4 with C=10000.0\n",
      "Cross-validating model with training data...\n",
      "\tCross-Validation Score: 0.958 Â± 0.026\n",
      "Fitting model to full training set...\n",
      "\tScore on training set: 0.975\n",
      "Saving Results...\n",
      "\n",
      " ------------------------------ \n",
      "\n",
      "Model #5 with C=1000000.0\n",
      "Cross-validating model with training data...\n",
      "\tCross-Validation Score: 0.958 Â± 0.037\n",
      "Fitting model to full training set...\n",
      "\tScore on training set: 0.983\n",
      "Saving Results...\n",
      "\n",
      " ------------------------------ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adjust the regularization C\n",
    "c_values = [1e-1, 1e2, 1e4, 1e6]\n",
    "\n",
    "# Start at #2 since we have \"model_1\" already\n",
    "for i, c in enumerate(c_values, start=2):\n",
    "    \n",
    "    print(f'Model #{i} with C={c}')\n",
    "    new_model = LogisticRegression(C=c, max_iter=1e3)\n",
    "    \n",
    "    # Cross-validation\n",
    "    print('Cross-validating model with training data...')\n",
    "    cv_results = cross_validate(\n",
    "                    estimator=new_model,\n",
    "                    X=X_train,\n",
    "                    y=y_train,\n",
    "                    cv=5,\n",
    "                    return_train_score=True\n",
    "    )\n",
    "    print(f'\\tCross-Validation Score: {cv_overall(cv_results)}')\n",
    "    \n",
    "    # Train/fit with the full training set\n",
    "    print('Fitting model to full training set...')\n",
    "    new_model.fit(X_train, y_train)\n",
    "    train_score = new_model.score(X_train, y_train)\n",
    "    print(f'\\tScore on training set: {train_score:.3f}')\n",
    "    \n",
    "    # Save results\n",
    "    print('Saving Results...')\n",
    "    models[f'model_{i}'] = {'model': new_model, 'cv': cv_results}\n",
    "    \n",
    "    print('\\n','-'*30,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000.0, max_iter=1000.0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models['model_5']['model']\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's get predictions for training & testing sets\n",
    "y_hat_train = best_model.predict(X_train)\n",
    "y_hat_test = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-Loss on Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05988733748274066\n",
      "0.101213855641447\n"
     ]
    }
   ],
   "source": [
    "print(log_loss(y_train, best_model.predict_proba(X_train)))\n",
    "print(log_loss(y_test, best_model.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values correctly predicted:\n",
      "True     118\n",
      "False      2\n",
      "Name: target, dtype: int64\n",
      "\n",
      " ------------------------------ \n",
      "\n",
      "Percentage of values correctly predicted: \n",
      "True     0.983333\n",
      "False    0.016667\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Was our model correct?\n",
    "residuals = y_train == y_hat_train\n",
    "\n",
    "print('Number of values correctly predicted:')\n",
    "print(pd.Series(residuals).value_counts())\n",
    "\n",
    "print('\\n','-'*30,'\\n')\n",
    "\n",
    "print('Percentage of values correctly predicted: ')\n",
    "print(pd.Series(residuals).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of values correctly predicted:\n",
      "True     28\n",
      "False     2\n",
      "Name: target, dtype: int64\n",
      "\n",
      " ------------------------------ \n",
      "\n",
      "Percentage of values correctly predicted: \n",
      "True     0.933333\n",
      "False    0.066667\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "residuals = y_test == y_hat_test\n",
    "\n",
    "print('Number of values correctly predicted:')\n",
    "print(pd.Series(residuals).value_counts())\n",
    "\n",
    "print('\\n','-'*30,'\\n')\n",
    "\n",
    "print('Percentage of values correctly predicted: ')\n",
    "print(pd.Series(residuals).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Split the data below into train and test, and then convert the y-values (`geysers.kind`) into 1's and 0's. Then use `sklearn` to build a logistic regression model of whether Old Faithful's eruption wait time is long or short, based on the duration of the eruption. Finally, find the points in the test set where the model's prediction differs from the true y-value. How many are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "geysers = sns.load_dataset('geyser', **{'usecols': ['duration', 'kind']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>kind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.600</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.800</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.333</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.283</td>\n",
       "      <td>short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.533</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration   kind\n",
       "0     3.600   long\n",
       "1     1.800  short\n",
       "2     3.333   long\n",
       "3     2.283  short\n",
       "4     4.533   long"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geysers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## More Generalizations: Other Link Functions, Other Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Logistic regression's link function is the logit function, but different sorts of models use different link functions.\n",
    "\n",
    "[Wikipedia](https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function) has a nice table of generalized linear model types and their associated link functions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
